{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e3993515-9710-4ac4-89e9-b35ebb81e920",
      "metadata": {
        "id": "e3993515-9710-4ac4-89e9-b35ebb81e920"
      },
      "source": [
        "# Large Language Models and Data Engineering pipelines\n",
        "\n",
        "Large Language Models (LLMs) such as GPT-4 and Claude are transforming how data engineers approach common challenges within data pipelines. By leveraging the power of natural language processing and prompt-based interactions, these models can automate, accelerate, and improve the accuracy of many data-related tasks that previously required manual intervention or extensive scripting.\n",
        "\n",
        "One of the most effective ways to use LLMs in data engineering is through prompting—that is, providing the model with carefully crafted instructions and example inputs so it can perform the desired task. This prompt-based approach allows LLMs to handle a wide range of data engineering activities without needing complex custom code for each scenario.\n",
        "\n",
        "In this notebook, we will explore how to use LLMs for various tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "MjMdFZzFCQZm"
      },
      "id": "MjMdFZzFCQZm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41df0348",
      "metadata": {
        "height": 132,
        "tags": [],
        "id": "41df0348"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key='YOUR_OPENAI_API_KEY',\n",
        "\n",
        ")\n",
        "\n",
        "#This is the main function that communicate with LLM. Temperature controls how random will your answer should be.\n",
        "#If you increase the temperature, running the same prompt twice may ends up in different answer\n",
        "def get_completion(prompt, model=\"gpt-4o\", temperature=0):\n",
        "    chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt,\n",
        "          }\n",
        "      ],\n",
        "      model=model,\n",
        "      temperature=temperature)\n",
        "    return chat_completion.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data cleaning\n",
        "\n",
        "LLMs can be prompted to standardize values, fix typos, and normalize formats. These tasks would otherwise require lengthy scripts and manual checking. By providing a few examples of messy data, you can ask the model to output a cleaned, standardized version of the same data."
      ],
      "metadata": {
        "id": "6GiRJsOnfFsK"
      },
      "id": "6GiRJsOnfFsK"
    },
    {
      "cell_type": "code",
      "source": [
        "cities = [\n",
        "    \"New York City\",\n",
        "    \"NYC\",\n",
        "    \"nyc\",\n",
        "    \"San Francisco\",\n",
        "    \"San Fran\",\n",
        "    \"sanfrancisco\",\n",
        "    \"Chicago\",\n",
        "    \"CHI\",\n",
        "    \"Los Angeles\",\n",
        "    \"LA\",\n",
        "    \"L.A.\",\n",
        "    \"los angeles\",\n",
        "    \"Boston\",\n",
        "    \"BOS\",\n",
        "    \"boston\",\n",
        "    \"Houston\",\n",
        "    \"H-Town\",\n",
        "    \"houston\",\n",
        "    \"Seattle\",\n",
        "    \"SEA\",\n",
        "    \"seattle\",\n",
        "    \"Washington D.C.\",\n",
        "    \"DC\",\n",
        "    \"Washington DC\",\n",
        "    \"Miami\",\n",
        "    \"MIA\",\n",
        "    \"miami\",\n",
        "    \"Dallas\",\n",
        "    \"DAL\",\n",
        "    \"dallas\"\n",
        "]\n",
        "\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "Below is a list of city names. Some entries are inconsistent or misspelled.\n",
        "Output a cleaned list where all city names are standardized.\n",
        "Only output the corrected city name.\n",
        "\n",
        "Example 1:\n",
        "Input: NYC\n",
        "Output: New York City\n",
        "\n",
        "Example 2:\n",
        "Input: San Fran\n",
        "Output: San Francisco\n",
        "\n",
        "Input: {}\n",
        "Output:\n",
        "\"\"\"\n",
        "\n",
        "for c in cities:\n",
        "  prompt = prompt_template.format(c);\n",
        "  response = get_completion(prompt)\n",
        "  print(response)\n"
      ],
      "metadata": {
        "id": "7_WxxJk7f6MH"
      },
      "id": "7_WxxJk7f6MH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Transformation\n",
        "\n",
        "LLMs excel at understanding and reformatting semi-structured or unstructured data, such as extracting structured fields from free-form text or reformatting address blocks into CSV rows. Well-designed prompts can instruct the model to output exactly the data format you need.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7r78ZF8viNCd"
      },
      "id": "7r78ZF8viNCd"
    },
    {
      "cell_type": "code",
      "source": [
        "addresses = [\n",
        "    \"Address is 1600 Amphitheatre Parkway Mountain View CA 94043\",\n",
        "    \"1 Apple Park Way Cupertino California, 95014\",\n",
        "    \"233 S Wacker Dr Chicago Ilinois Zip: 60606\"\n",
        "]\n",
        "\n",
        "prompt_template = \"\"\"Extract street address, city, state, and ZIP code from the following lines and output\n",
        "as CSV rows in the order: street, city, state, zip. Use 2 letter state code for consistency. Only respond with comma separated entries for each address.\n",
        "\n",
        "text: {}\n",
        "output: \"\"\n",
        "\"\"\"\n",
        "\n",
        "for address in addresses:\n",
        "  prompt = prompt_template.format(address);\n",
        "  response = get_completion(prompt)\n",
        "  print(response)\n"
      ],
      "metadata": {
        "id": "X75_1W-kifV4"
      },
      "id": "X75_1W-kifV4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Scraping\n",
        "\n",
        "LLMs can parse through messy text or code, identify relevant fields (like product names and prices), and produce clean, machine-readable outputs. Prompting the LLM with an example HTML snippet and clear extraction instructions enables quick and accurate information retrieval.\n",
        "\n"
      ],
      "metadata": {
        "id": "IYQgZKvwkNJd"
      },
      "id": "IYQgZKvwkNJd"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Given the HTML below, extract all product names and their prices. Output as a two-column CSV with headers: product, price.\n",
        "\n",
        "<html>\n",
        "  <div class=\"product\">\n",
        "    <span class=\"name\">Wireless Mouse</span>\n",
        "    <span class=\"price\">$15.99</span>\n",
        "  </div>\n",
        "  <div class=\"product\">\n",
        "    <span class=\"name\">USB-C Adapter</span>\n",
        "    <span class=\"price\">$8.49</span>\n",
        "  </div>\n",
        "  <div class=\"product\">\n",
        "    <span class=\"name\">Bluetooth Keyboard</span>\n",
        "    <span class=\"price\">$22.00</span>\n",
        "  </div>\n",
        "</html>\n",
        "\n",
        "Output:\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "6qSnxh5tkcuH"
      },
      "id": "6qSnxh5tkcuH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1d8f0bd8-628e-4c36-bcd0-2110162f25fc",
      "metadata": {
        "id": "1d8f0bd8-628e-4c36-bcd0-2110162f25fc"
      },
      "source": [
        "## Translation\n",
        "\n",
        "Large language models are trained with sources in many languages. This gives the model the ability to do translation. Here are some examples of how to use this capability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c4df6ff",
      "metadata": {
        "height": 115,
        "tags": [],
        "id": "9c4df6ff"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following English text to Spanish: \\\n",
        "```Hi, I would like to order a blender```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7300ed9b",
      "metadata": {
        "height": 115,
        "tags": [],
        "id": "7300ed9b"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Tell me which language this is:\n",
        "```Combien coûte le lampadaire?```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "791e789b",
      "metadata": {
        "height": 132,
        "tags": [],
        "id": "791e789b"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following  text to French and Spanish\n",
        "and English pirate: \\\n",
        "```I want to order a basketball```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcf7eb63",
      "metadata": {
        "height": 132,
        "tags": [],
        "id": "fcf7eb63"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following text to Spanish in both the \\\n",
        "formal and informal forms:\n",
        "'Would you like to order a pillow?'\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8edb56d2-a32a-470f-9f40-4fc5b1ea0849",
      "metadata": {
        "id": "8edb56d2-a32a-470f-9f40-4fc5b1ea0849"
      },
      "source": [
        "### Universal Translator\n",
        "Imagine you are in charge of IT at a large multinational e-commerce company. Users are messaging you with IT issues in all their native languages. Your staff is from all over the world and speaks only their native languages. You need a universal translator!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68a40bf0",
      "metadata": {
        "height": 132,
        "tags": [],
        "id": "68a40bf0"
      },
      "outputs": [],
      "source": [
        "user_messages = [\n",
        "  \"La performance du système est plus lente que d'habitude.\",  # System performance is slower than normal\n",
        "  \"Mi monitor tiene píxeles que no se iluminan.\",              # My monitor has pixels that are not lighting\n",
        "  \"Il mio mouse non funziona\",                                 # My mouse is not working\n",
        "  \"Mój klawisz Ctrl jest zepsuty\",                             # My keyboard has a broken control key\n",
        "  \"我的屏幕在闪烁\"                                               # My screen is flashing\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "552d0db9",
      "metadata": {
        "height": 200,
        "tags": [],
        "id": "552d0db9"
      },
      "outputs": [],
      "source": [
        "for issue in user_messages:\n",
        "    prompt = f\"Tell me what language this is: ```{issue}```\"\n",
        "    lang = get_completion(prompt)\n",
        "    print(f\"Original message ({lang}): {issue}\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Translate the following  text to English \\\n",
        "    and Korean: ```{issue}```\n",
        "    \"\"\"\n",
        "    response = get_completion(prompt)\n",
        "    print(response, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18e660eb-324f-474c-acf3-7e3bf5b7c70e",
      "metadata": {
        "id": "18e660eb-324f-474c-acf3-7e3bf5b7c70e"
      },
      "source": [
        "## Try it yourself!\n",
        "Try some translations on your own!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa57158f-d77d-42d1-94fe-17fa59c012f8",
      "metadata": {
        "height": 30,
        "id": "fa57158f-d77d-42d1-94fe-17fa59c012f8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1d9e54ca-f93a-43c8-a295-bff7a89f77f5",
      "metadata": {
        "id": "1d9e54ca-f93a-43c8-a295-bff7a89f77f5"
      },
      "source": [
        "## Tone Transformation\n",
        "Writing can vary based on the intended audience. LLMs can produce different tones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2deac328",
      "metadata": {
        "height": 115,
        "tags": [],
        "id": "2deac328"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Translate the following from slang to a business letter:\n",
        "'Dude, This is Joe, check out this spec on this standing lamp.'\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2c7eb73-6b82-442d-b4f8-251c308e89d5",
      "metadata": {
        "id": "a2c7eb73-6b82-442d-b4f8-251c308e89d5"
      },
      "source": [
        "## Format Conversion\n",
        "LLMs can translate between formats. The prompt should describe the input and output formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a37f0a0",
      "metadata": {
        "height": 217,
        "tags": [],
        "id": "5a37f0a0"
      },
      "outputs": [],
      "source": [
        "data_json = { \"resturant employees\" :[\n",
        "    {\"name\":\"Shyam\", \"email\":\"shyamjaiswal@gmail.com\"},\n",
        "    {\"name\":\"Bob\", \"email\":\"bob32@gmail.com\"},\n",
        "    {\"name\":\"Jai\", \"email\":\"jai87@gmail.com\"}\n",
        "]}\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Translate the following python dictionary from JSON to an HTML \\\n",
        "table with column headers and title: {data_json}\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "481a46b7",
      "metadata": {
        "height": 47,
        "tags": [],
        "id": "481a46b7"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown, Latex, HTML, JSON\n",
        "display(HTML(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2df1824c-534b-45cb-b0c1-3000bba5adbe",
      "metadata": {
        "id": "2df1824c-534b-45cb-b0c1-3000bba5adbe"
      },
      "source": [
        "## Spellcheck/Grammar check.\n",
        "\n",
        "Here are some examples of common grammar and spelling problems and the LLM's response.\n",
        "\n",
        "To signal to the LLM that you want it to proofread your text, you instruct the model to 'proofread' or 'proofread and correct'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d77283",
      "metadata": {
        "height": 302,
        "tags": [],
        "id": "52d77283"
      },
      "outputs": [],
      "source": [
        "text = [\n",
        "  \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.\n",
        "  \"Yolanda has her notebook.\", # ok\n",
        "  \"Its going to be a long day. Does the car need it’s oil changed?\",  # Homonyms\n",
        "  \"Their goes my freedom. There going to bring they’re suitcases.\",  # Homonyms\n",
        "  \"Your going to need you’re notebook.\",  # Homonyms\n",
        "  \"That medicine effects my ability to sleep. Have you heard of the butterfly affect?\", # Homonyms\n",
        "  \"This phrase is to cherck chatGPT for speling abilitty\"  # spelling\n",
        "]\n",
        "for t in text:\n",
        "    prompt = f\"\"\"Proofread and correct the following text\n",
        "    and rewrite the corrected version. If you don't find\n",
        "    and errors, just say \"No errors found\". Don't use\n",
        "    any punctuation around the text:\n",
        "    ```{t}```\"\"\"\n",
        "    response = get_completion(prompt)\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7543fe7d",
      "metadata": {
        "height": 234,
        "tags": [],
        "id": "7543fe7d"
      },
      "outputs": [],
      "source": [
        "text = f\"\"\"\n",
        "Got this for my daughter for her birthday cuz she keeps taking \\\n",
        "mine from my room.  Yes, adults also like pandas too.  She takes \\\n",
        "it everywhere with her, and it's super soft and cute.  One of the \\\n",
        "ears is a bit lower than the other, and I don't think that was \\\n",
        "designed to be asymmetrical. It's a bit small for what I paid for it \\\n",
        "though. I think there might be other options that are bigger for \\\n",
        "the same price.  It arrived a day earlier than expected, so I got \\\n",
        "to play with it myself before I gave it to my daughter.\n",
        "\"\"\"\n",
        "prompt = f\"proofread and correct this review: ```{text}```\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b4e73fd",
      "metadata": {
        "height": 149,
        "tags": [],
        "id": "2b4e73fd"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "proofread and correct this review. Make it more compelling.\n",
        "Ensure it follows APA style guide and targets an advanced reader.\n",
        "Output in markdown format.\n",
        "Text: ```{text}```\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "display(Markdown(response))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2b2ca58",
      "metadata": {
        "height": 30,
        "id": "a2b2ca58"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}