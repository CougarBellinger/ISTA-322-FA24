{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Submission Instruction**\n",
        "1. Save a copy in your drive and replace blank with your name\n",
        "\n",
        "2. Run all the cells and complete the answer to the question at the end of the notebook\n",
        "\n",
        "3. Download the .ipynb file and submit on Gradescope\n",
        "\n"
      ],
      "metadata": {
        "id": "VzAXMo5TWvKy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5WKTjWAm1NB"
      },
      "source": [
        "# JSON Flattening and Transforms w/ Spotify Data\n",
        "\n",
        "This week we're going to be learning how to do transforms with JSON data.  Spotify has a wonderful API that allows access to a ton of their data.  The Spotipy package offers a nice python interface to access that.  \n",
        "\n",
        "Calls to Spotify yield info on artists/albums/songs all in JSON format.  The goal will be to get artist info along with info on the top 10 songs.  We'll then do some graphical views into the musical preferences of you all!\n",
        "\n",
        "We'll start by just working through the pipeline with a single artist.  After we learn how to wrangle data of just one artist we'll expand to a big list of artists to make our full dataset.  This takes some looping to make work so figure let's learn to deal with the JSONs first, then the loops.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjDWbXK1rgpw"
      },
      "source": [
        "## First, installing packages into Colab\n",
        "\n",
        "The spotipy package isn't preinstalled in Colab, so we gotta do that.  You can do a regular pip install:\n",
        "\n",
        "`!pip install spotipy`\n",
        "\n",
        "But the obvious issue here is that this isn't a permanent install, so if you close your notebook and come back later the install will be gone and you'll have to redo it.  Not a huge deal, but also annoying with larger packages.  \n",
        "\n",
        "What we'll do instead is mount your google drive and install the package to that.  This way whenever you come back your drive will (should) remount and you can load up the package as you normally would.\n",
        "\n",
        "**Note** You obviously don't have to do this if working locally."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhbgLIoYssLv"
      },
      "source": [
        "### First - Mount your drive and give access\n",
        "\n",
        "The code below brings in some utilities and then provides the paths to the notebook and where to install.  The first time you run this in a new notebook you'll have to follow the link, copy the access key and then put into the open cell and hit enter.  After you've done that once the drive should mount automatically when you reopen. *But* I've found that this can be a bit picky so post to Slack if you're having trouble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi92Ox8FbgWE"
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/mnt')\n",
        "nb_path = '/content/notebooks'\n",
        "os.symlink('/content/mnt/My Drive/Colab Notebooks', nb_path)\n",
        "sys.path.insert(0, nb_path)  # or append(nb_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/mnt')\n",
        "nb_path = '/content/notebooks'\n",
        "sys.path.insert(0, nb_path)  # or append(nb_path)"
      ],
      "metadata": {
        "id": "UmSvaFID__d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Ykt82QtN8i"
      },
      "source": [
        "### Install library\n",
        "\n",
        "This is a regular install but you're telling it to install that into the notebook path in your drive created above.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeNRrBZgd7Cu"
      },
      "outputs": [],
      "source": [
        "# Install only once. Tomorrow, you can skip this.\n",
        "!pip install --target=$nb_path spotipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXJpT-Bptnk1"
      },
      "source": [
        "## Getting Spotipy up and running\n",
        "\n",
        "Getting spotipy working is pretty easy!  Here's a step-by-step breakdown.\n",
        "\n",
        "1.   Go to Spotify Developer Dashboard here: https://developer.spotify.com/dashboard\n",
        "2.   Sign up to create an account\n",
        "3.   After sign up click on your name on the top and select Dashboard\n",
        "4.   Verify your email address and reload the page\n",
        "5.   Click 'CREATE AN APP' button in upper right\n",
        "6.   Give it a name and description (the description doesn't matter). For redirect address you can use (https://www.google.com).\n",
        "Check both Web API and Web Playback SDK\n",
        "7.   Click create\n",
        "8.   On the new page it'll show your Client ID and a 'Show Client Secret' line of text\n",
        "9.   Show the secret.   You'll need that and your ID for the next step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TtkDvS1LLCeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaLBiihnvEr5"
      },
      "source": [
        "###  Import spotipy and inputting credentials\n",
        "\n",
        "In the cell below paste in your unique ID and secret and then run the cell.\n",
        "\n",
        "We don't alias spotipy, but we do link the credentials to an object called `sp`.  This acts as an alias to spotipy while also providing those."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSggdPGNfIoj"
      },
      "outputs": [],
      "source": [
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "\n",
        "\n",
        "\n",
        "spotify_client_id = ''\n",
        "spotify_client_secret  = ''\n",
        "\n",
        "client_credentials_manager = SpotifyClientCredentials(\n",
        "    client_id=spotify_client_id,\n",
        "    client_secret=spotify_client_secret\n",
        ")\n",
        "\n",
        "sp = spotipy.Spotify(\n",
        "    client_credentials_manager=client_credentials_manager\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5D3LDpZvhZv"
      },
      "source": [
        "## Working with a single artist\n",
        "\n",
        "Let's dig in!  We're going to start with just getting info and making things work with just a single artist.  In this case we're going to get the top 10 songs and features by the artist Dance With The Dead.  \n",
        "\n",
        "You'll see that we actually need to make a range of calls to Spotify in order to build this dataset.  This is because their database is normalized where artist info is in a different database than album info, and those are different from song features...  you get the idea.  \n",
        "\n",
        "The key thing you need here is the artist URI (the unique identifier).  If you look at the image below you'll see that if you click the `...` you then then scroll to share and then copy the URI. It gives you the following \"spotify:artist:2KtnZQwMQJN3uyI8eHZRvm\"\n",
        "\n",
        "![image](https://drive.google.com/uc?export=view&id=1SKmM94qeG0DSWZTaxQ13yQUUu3tGZ-_5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypsZqbtEyJoo"
      },
      "source": [
        "### Getting artist info\n",
        "\n",
        "First thing we're going to do is call the `artist()` function on our ID and see what that gets us!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VxB7jIeyYtY"
      },
      "outputs": [],
      "source": [
        "# libraries too :)\n",
        "import pandas as pd\n",
        "from pandas import json_normalize\n",
        "\n",
        "# First, let's get an artist.  Note that you can also copy just the URI.\n",
        "art = sp.artist('spotify:artist:2KtnZQwMQJN3uyI8eHZRvm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LM1xVXU5Nja"
      },
      "outputs": [],
      "source": [
        "# Check it out\n",
        "art"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4-JalKkyrm5"
      },
      "source": [
        "### Just a little JSON\n",
        "\n",
        "Yep, so our object `art` is a JSON with a bunch of info about the band. A lot of that info is nested as well.  Let's work through it a bit.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V21dk0lyqR-"
      },
      "outputs": [],
      "source": [
        "# First, what keys are there?\n",
        "art.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezPUNbfLznxy"
      },
      "outputs": [],
      "source": [
        "# Artist name\n",
        "print(art['name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9fsOzae5ft_"
      },
      "outputs": [],
      "source": [
        "# Can you get how many total followers there are?  It's two levels deep\n",
        "print(art['followers']['total'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvISzRs65mQR"
      },
      "outputs": [],
      "source": [
        "# Grab the genre of music\n",
        "print(art['genres'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEmLuEx_8BXN"
      },
      "source": [
        "### Mapping that JSON to a data frame\n",
        "\n",
        "OK, so you can call up different bits from that JSON using square brackets.  But, the whole point of this is to get the data into a more useful format for analysis, which in this case means a flat structure.\n",
        "\n",
        "We're going to eventually be working with a long list of artist URIs, so we're going to make a function to extract out those elements to a list.  Then later we can use `map()` to apply that function to each element of the list.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxEMNKNK8AlQ"
      },
      "outputs": [],
      "source": [
        "# To start, you can store just a single element of that above JSON like anything else\n",
        "artist_name = art['name']\n",
        "artist_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0Khy7oJ9kQe"
      },
      "source": [
        "So let's make a function to extract the name, id, number of followers, and first entry of genre.\n",
        "\n",
        "If you're rusty, remember that you define a function with the following:\n",
        "```\n",
        "def function_name(arguments):\n",
        "  action\n",
        "  action\n",
        "  return(whatever you want to have returned)\n",
        "```\n",
        "\n",
        "We're going to make a function called 'get_artist_info'.  This function will take an artist ID and then store the name, id, followers, and genre, and then add them all into a list.  The return will be that list as it'll be easy to turn into a dataframe!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3lkKJbh2SyI"
      },
      "outputs": [],
      "source": [
        "#I'll make this function for you!\n",
        "\n",
        "def get_artist_info(art_id): # define name and argument\n",
        "  art_json = sp.artist(art_id) # calling out to the spotipy function using the art_id that was given\n",
        "  name = art_json['name'] # use that json object to get name\n",
        "  id = art_json['id'] # artist id\n",
        "  followers = art_json['followers']['total'] #down a level in followers to get total number\n",
        "  genre = art['genres'][0] #extracting just the first genre in the list\n",
        "  art_list = [name, id, followers, genre] # make a list\n",
        "  return(art_list) # have your function return that list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIAWC2hQ2wXf"
      },
      "outputs": [],
      "source": [
        "# Let's call our function on the URI from Dance with the Dead (feel free to try with other artists!)\n",
        "art_list = get_artist_info('2KtnZQwMQJN3uyI8eHZRvm')\n",
        "art_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbmKgivZ36JP"
      },
      "outputs": [],
      "source": [
        "# Now we can turn that list into a dataframe using pd.DataFrame()\n",
        "# You need to provide the list and then a list of column names\n",
        "# We'll store this as 'artist_info'\n",
        "artist_info = pd.DataFrame(data = [art_list], columns = ['name', 'id', 'followers', 'genre'])\n",
        "artist_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClsYyONIBqYb"
      },
      "source": [
        "## Now to get the top tracks\n",
        "\n",
        "Now that we have the artist info we can get their top 10 tracks.  The function `artist_top_tracks()` returns just that if you give it an ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U9U-wJ6E_j4"
      },
      "outputs": [],
      "source": [
        "# Assign top 10 songs to artist_top\n",
        "artist_top = sp.artist_top_tracks(artist_info['id'][0])\n",
        "artist_top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPOolq-RClFi"
      },
      "outputs": [],
      "source": [
        "# The topmost key is 'tracks' which makes sense as it's 10 indivdiual tracks\n",
        "artist_top.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dImAiyiFC6Gr"
      },
      "outputs": [],
      "source": [
        "# Let's look at just the second track\n",
        "artist_top['tracks'][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_duZ1zrCjmp"
      },
      "source": [
        "### Using pandas to normalize our JSONs\n",
        "\n",
        "So that returned a pretty large json with a lot of information.  We could go and write another function to pull out the information for each track, but instead we're going to use some of the built-in `pandas` JSON parsing functions.  \n",
        "\n",
        "`json_normalize()` will take that JSON data and turn it into a dataframe.  Let's apply it and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-xZRcrdDjVQ"
      },
      "outputs": [],
      "source": [
        "# Well this isn't helpful\n",
        "# The issue is that the data are all down a level under 'tracks'\n",
        "pd.json_normalize(artist_top)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuGfFM7kDt4w"
      },
      "outputs": [],
      "source": [
        "# Let's call it on artist_top['tracks']\n",
        "# Add .head(3) just to see only the first few.\n",
        "pd.json_normalize(artist_top['tracks']).head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPjWQaw1EYpj"
      },
      "source": [
        "So that worked well overall!  You can see it made columns for all the levels directly under 'tracks'.  \n",
        "\n",
        "But, there's also information we want that's deeper in the JSON. For example, 'artist' has the artist name and id under it, both of which we'll need to bring our data together.  See below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvHCMHXUE0gu"
      },
      "outputs": [],
      "source": [
        "artist_top['tracks'][1]['artists']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI-vAo0LFIyW"
      },
      "source": [
        "Luckily `json_normalize()` has more functionality.  You can tell it what path you want it to  normalize with `record_path = ['level you want']`\n",
        "\n",
        "Let's try it.  Note I tossed in one more argument... `sep = '_'`. `json_normalize()` defaults to using periods as separators, but you should never use those so this'll change it to underscores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stSMD6sIFIDG"
      },
      "outputs": [],
      "source": [
        "# Try it!\n",
        "pd.json_normalize(artist_top['tracks'], record_path=['artists'], sep='_').head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nFHh9bjdUlv"
      },
      "source": [
        "Wait, that got us now our individual data about the artist, but now we lost the data about the songs themselves!\n",
        "\n",
        "Not to worry, though. You can use the meta = [] to provide a list of other information you want to attach from the json.\n",
        "\n",
        "Let's get the track id, track name, popularity, and duration. The code would look like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x87zgBJRZMFU"
      },
      "outputs": [],
      "source": [
        "pd.json_normalize(artist_top['tracks'],\n",
        "                  record_path=['artists'],\n",
        "                  meta = ['id', 'name', 'popularity', 'duration_ms'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulunCwpGdfvh"
      },
      "source": [
        "But that throws us an error saying that there's conflicting metadata.\n",
        "\n",
        "There's an issue here that should hopefully be pretty apparent. Notice above that it also gives us the id contained in the artist section. But we obviously want the song id so we can get that info next. This'll cause a conflict as we'll then have two columns named the same. We can fix this by adding in two other arguments that tell it what prefix to give both the metadata and the record data. Given our record is asking for artist info, let's give that a prefix of 'artist_' and our meta is asking for track info we'll give that 'track_'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kr9zlfz6digS"
      },
      "outputs": [],
      "source": [
        "pd.json_normalize(artist_top['tracks'],\n",
        "  record_path=['artists'],\n",
        "  meta = ['id', 'name', 'popularity', 'duration_ms'],\n",
        "  record_prefix = 'artist_',\n",
        "  meta_prefix = 'track_',\n",
        "  sep = '_')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPCuu9TJWDS2"
      },
      "outputs": [],
      "source": [
        "# Lets store our data this time as top_track_info\n",
        "top_track_info = pd.json_normalize(artist_top['tracks'],\n",
        "                  record_path=['artists'],\n",
        "                  meta = ['id', 'name','popularity', 'duration_ms'],\n",
        "                  record_prefix = 'artist_',\n",
        "                  meta_prefix = 'track_',\n",
        "                  sep = '_')\n",
        "\n",
        "top_track_info.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iXvW_EzJsJB"
      },
      "outputs": [],
      "source": [
        "# Let's keep just the columns we need.\n",
        "# We're going to call for song specifics using track ID, but we'll also want artist ID and name for later.\n",
        "top_track_info = top_track_info[['artist_name', 'artist_id', 'track_id', 'track_name', 'track_popularity', 'track_duration_ms']]\n",
        "top_track_info.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJwVu4yoJ40x"
      },
      "source": [
        "OK great!  We've managed to get data from within different levels of our JSON return and wrangle that into a dataframe.  \n",
        "\n",
        "One issue though.... notice that we have places where there are duplicates of the track ID/name but two different artists.  In this case there were two artists on a single track, so we have an entry for each.  This might not be a big deal, but we're going to want to drop those and just keep the main artist.  This is because our end goal is to aggregate by artist, and don't want to run those on artists with only one song that just happened to colloborate. In other situations, we might want to keep these. As always, it depends on what the goal is/what the end user plans to do with the data.\n",
        "\n",
        "There's an easy way to deal with this.  Let's just filter our `top_track_info` dataframe to include only rows where the `artist_id` matches the `artist_name` in our `artist_info` data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yODeF3HJJoCB"
      },
      "outputs": [],
      "source": [
        "# I'm going to filter our dataframe and use the .isin() function.\n",
        "# This is asking if a level in artist_name from top_track_info is ever seen in the artist_name column in our earlier artist_info dataframe.\n",
        "print('before: ' +  ', '.join(top_track_info['artist_name'].unique())) # before\n",
        "top_track_info = top_track_info[top_track_info['artist_name'].isin(artist_info['name'])]\n",
        "\n",
        "# check to verify!\n",
        "print('after: ' +  ', '.join(top_track_info['artist_name'].unique())) # after"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#final check to see what we have\n",
        "top_track_info"
      ],
      "metadata": {
        "id": "HIqQul2X3Qal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QImjV6y2MuGn"
      },
      "source": [
        "## Joining our data\n",
        "\n",
        "Major progress!  We now have two dataframes.  One has the artist info, another with top 10 songs and their ID. How can we get those data together?  Joins!\n",
        "\n",
        "We're going to go over joins in more detail when we jump into the SQL world.  But for now, I'll give you some bullet points.\n",
        "\n",
        "*   People typically think of the dataframes they want to join as 'left' and 'right'\n",
        "*   The left can be thought of as the base and then the right is what you join to it\n",
        "*   You join based on a key.  They key is what links the left data frame to the right data frame\n",
        "*   When you do what's called a 'left join' you will attach all the info from the right data frame to its corresponding row (based on the key) to the left data frame.  \n",
        "\n",
        "\n",
        "A bit about the python function `.merge()` which you use for your dataframe.  The syntax is as follows\n",
        "```\n",
        "left_df.merge(right_df,\n",
        "  left_on = 'key in left df',\n",
        "  right_on = 'key in right',\n",
        "  how = 'type of join')\n",
        "  ```\n",
        "In this case we want to have the `top_track_info` be our left and then `artist_info` be our right.  The key between them is the artist ID, but that may have a different name in each.  So for `left_on` we want to specify the column `artist_id`, but in the `right_on` we use just `id` as that's what the column is called in `artist_info`.  We want to do a left join so we use `how = 'left'`.\n",
        "\n",
        "Visually this is what the join will do:\n",
        "\n",
        "![image](https://drive.google.com/uc?export=view&id=1199S0cnarbs4ROVxkPkThtovCOd97eVi)\n",
        "\n",
        "\n",
        "Let's try it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQTDnvHKp6gb"
      },
      "outputs": [],
      "source": [
        "# A reminder of what's in artist_info\n",
        "artist_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4x-6jfNZcGK"
      },
      "outputs": [],
      "source": [
        "# Do a left join with artist info.\n",
        "top_track_info = top_track_info.merge(artist_info, left_on = 'artist_id', right_on= 'id', how = 'left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJdGBwudo2e7"
      },
      "source": [
        "Great!  So that did the trick!  You can see that the artist_id and id columns have the same values.  So what `.merge()` did was take the left data frame, then grab the row from the right data frame that had the matching key and added it to the left.  \n",
        "\n",
        "When we do the left join if there is no similar artist id on right, then the artist info on the left will be filled with Nan values.\n",
        "\n",
        "It is important to note that the number of rows in result dataframe will be the same as the number of rows in the left dataframe of the join."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_track_info"
      ],
      "metadata": {
        "id": "sEXM1RA220wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Looking at the far right of the dataframe you can see that it added on the number of followers and genre to every row of the dataframe.  \n",
        "You also notice duplicate columns id and name for artist.  You could go and drop those."
      ],
      "metadata": {
        "id": "ATEjaZpgfwlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#now we can drop the extra id and name column and only keep followers and genra from artist info\n",
        "top_track_info = top_track_info.drop(columns = ['id', 'name'])\n",
        "top_track_info"
      ],
      "metadata": {
        "id": "0pFhKjeUCjAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2fykdG8qJ9Q"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "OK, so at this point we pulled from two different datasets in JSON format and brought them together into one single data frame that could be used for visualization, analysis, or recommendations.  Of course, we want more artists in this dataset to do those things so now we're going to build this out to get information from more artists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnQHe4QJrqUl"
      },
      "source": [
        "## Making this work with lots of artists\n",
        "\n",
        "In general this isn't a huge deal if you remember how to leverage some of your python skills.  We'll be using two general ways of repeating a process.  Map and loops.  \n",
        "\n",
        "The `map()` function will take the function we wrote earlier and execute it across a list of values. For loops will be used as well for a similar purpose.  I'm showing you both just to get you practice!  Let's dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NERfLX6-sKaw"
      },
      "source": [
        "### Starting with a list of artists\n",
        "\n",
        "Here's a list of the URIs for different artists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7xc6vMssTgr"
      },
      "outputs": [],
      "source": [
        "artist_list = ['1Mxqyy3pSjf8kZZL4QVxS0', '2KtnZQwMQJN3uyI8eHZRvm', '4UXqAaa6dQYAk18Lv7PEgX', '7yRimuQSC5Ks3T2Ts0iyZa', '5Ho1vKl1Uz8bJlk4vbmvmf', '7tYKF4w9nC0nq9CsPZTHyP',\n",
        "               '4q3ewBCX7sLwd24euuV69X', '6ueGR6SWhUJfvEhqkvMsVs', '5WY88tCMFA6J6vqSN3MmDZ', '5DIi2JWfQPTKffaVBlIYRn',\n",
        "               '2qxJFvFYMEDqd7ui6kSAcq', '2o5jDhtHVPhrJdv3cEQ99Z', '3EA9hVIzKfFiQI0Kikz2wo', '6nxWCVXbOlEVRexSbLsTer', '49gaZqfow2v8EEQmjGyEIw',\n",
        "               '3TVXtAsR1Inumwj472S9r4', '711MCceyCBcFnzjGY4Q7Un',  '7oPftvlwr6VrsViSDV7fJY', '3Uobr6LgQpBbk6k4QGAb3V',\n",
        "               '0FI0kxP0BWurTz8cB8BBug', '2CIMQHirSU0MQqyYHq0eOx', '0ZMWrgLff357yxLyEU77a1',\n",
        "               '6l3HvQ5sa6mXTsMTB19rO5', '4O15NlyKLIASxsJ0PrXPfz', '7F9ZL4TJNr8AoU0UUQX8ih' ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chUbpho6sWQR"
      },
      "outputs": [],
      "source": [
        "# Here's our function again\n",
        "def get_artist_info(art_id): # define name and argument\n",
        "  print(art_id)\n",
        "  art_json = sp.artist(art_id) # calling out to the spotipy function using the art_id that was given\n",
        "  artist_name = art_json['name'] # use that json object to get name\n",
        "  artist_id = art_json['id'] # artist id\n",
        "  followers = art_json['followers']['total'] #down a level in followers to get total number\n",
        "  genre = art_json['genres'][0] #extracting just the first genre in the list\n",
        "  art_list = [artist_name, artist_id, followers, genre] # make a list\n",
        "  return(art_list) # have your function return that list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfR3CFn_u83B"
      },
      "outputs": [],
      "source": [
        "# Note that it would work if we just called an element of artist_list by it's index\n",
        "for u in range(len(artist_list)):\n",
        "  try:\n",
        "    print(u, get_artist_info(artist_list[u]))\n",
        "  except:\n",
        "    print(artist_list[u], \"not working\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyfTnq7fsw7Q"
      },
      "source": [
        "### Using `map()`\n",
        "\n",
        "Let's use `map()` to apply our function `get_artist_info` to every element in `artist_list`.  The syntax is:\n",
        "`map(function to apply, list to apply function to)`.\n",
        "\n",
        "So in this case, it'll grab the first id from the list, apply our function to it, store it, go to the next id, store it, and so on.\n",
        "\n",
        "Let's give it a go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0ir46JXsltU"
      },
      "outputs": [],
      "source": [
        "# Apply get_artist_info function to artist_list and store as artist_info\n",
        "artist_info = map(get_artist_info, artist_list)\n",
        "artist_info #check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1O5fY6rtoy2"
      },
      "source": [
        "So it appears to have worked, but it created a map object which isn't immediately useful.  We need to tell python that we want it as a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzmfxcPStm9V"
      },
      "outputs": [],
      "source": [
        "# Apply the list() function to our map object\n",
        "artist_info = list(artist_info)\n",
        "len(artist_info) # check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD_XlA9guCn-"
      },
      "source": [
        "Great, now we have a bunch of lists each with artist info.  Now we can go and convert that into a dataframe like we did earlier in the lesson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps-jo2QNuLfq"
      },
      "outputs": [],
      "source": [
        "# Same syntax as before but this time I just told it to use different data!\n",
        "artist_info = pd.DataFrame(data = artist_info, columns= ['name', 'id', 'followers', 'genre'])\n",
        "artist_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-L57svlCybl"
      },
      "source": [
        "###  Getting top songs for all artists\n",
        "\n",
        "Great, so now we have a data frame with all the artists suggested by the class.  Just like before, we want to get the top 10 songs for each artist.  \n",
        "\n",
        "To do this we need to call the spotify function `sp_artist_top_tracks()` on each ID in that dataframe.  We obviously don't want to do this for every one manually, so we need to either make another function and use `map()` or we can use a for loop.  Let's use a loop so you can see how they work.  \n",
        "\n",
        "I'm going to make a short lesson on loops that you can go check out if you don't know how they work.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HNOGqXUEQYZ"
      },
      "source": [
        "#### Writing our loop\n",
        "\n",
        "We know a few things about the needs for ouu loop:\n",
        "\n",
        "* We want the top track info for all artists.  This means we want the loop to run as long as the artist list is.  \n",
        "* This will return a dataframe of top songs for each artist\n",
        "* We only need the four columns we used before\n",
        "* We'll need to make an empty dataframe and append to that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LklqcNoWEuqZ"
      },
      "outputs": [],
      "source": [
        "# First, let's make an empty dataframe\n",
        "top_track_info = list()\n",
        "top_track_info # Note it's empty in the return below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzWEc5lXDGTS"
      },
      "outputs": [],
      "source": [
        "# Now for our loop\n",
        "# We'll use range(len(artist_l)) so it knows to run for as long as the artists dataframe is\n",
        "for i in range(len(artist_info)):\n",
        "  art_top = sp.artist_top_tracks(artist_info['id'][i]) #Call our spotipy function in the i'th element!\n",
        "  top_tracks = pd.json_normalize(art_top['tracks'], record_path=['artists'], meta = ['id', 'name', 'popularity', 'duration_ms'], record_prefix = 'artist_', meta_prefix = 'track_', sep = '_') # Flatten\n",
        "  top_tracks = top_tracks[['artist_name', 'artist_id', 'track_id', 'track_name', 'track_popularity', 'track_duration_ms']] # Select just the columns we need\n",
        "  top_track_info.append(top_tracks)\n",
        "top_track_info = pd.concat(top_track_info) # .concat takes the list of dataframes and construct a new dataframe by stacking all of the items on the list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64dtfCDVGltm"
      },
      "source": [
        "That seems to have worked.  Let's check the shape, head and tail of top_tracks_info which is the dataframe that we filled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRQPhMBEF7vv"
      },
      "outputs": [],
      "source": [
        "# Check the shape...\n",
        "# More rows than we'd expect, but that makes sense if multiple artists can be tied to a single track.\n",
        "top_track_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LblBh-b7G8KF"
      },
      "outputs": [],
      "source": [
        "# Head looks good.  And can see an example of another artist being linked to the same top track.\n",
        "# Not a big deal, but explains why our row count is a bit inflated\n",
        "top_track_info.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-iOfcC2HITJ"
      },
      "outputs": [],
      "source": [
        "# how does the tail look?\n",
        "top_track_info.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iPSLb4EHOXT"
      },
      "source": [
        "OK, so our top tracks look good!  Let's deal with those duplicate rows as we did before.  We'll filter out rows where the artist id appeared in our original artist_info dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6sVHekEHd-x"
      },
      "outputs": [],
      "source": [
        "# Filter and check the length\n",
        "top_track_info = top_track_info[top_track_info['artist_id'].isin(artist_info['id'])]\n",
        "top_track_info.shape # Great a lot shorter and where we'd expect it to be."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_track_info"
      ],
      "metadata": {
        "id": "2vRUaQiqpnzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stla1n6bM2Ea"
      },
      "source": [
        "### Joining our data\n",
        "\n",
        "Now let's join everything together just like before.  We'll do a left joint to attach the artist info to our track info.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daNG0qJ3nnH0"
      },
      "outputs": [],
      "source": [
        "# And another to join our artist info to our top_track_info data frame\n",
        "# Join artist info.\n",
        "top_track_info = top_track_info.merge(artist_info, left_on = 'artist_id', right_on= 'id', how = 'left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2-2hGM6Ni3r"
      },
      "outputs": [],
      "source": [
        "# Check!\n",
        "top_track_info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRCNxjLVro96"
      },
      "source": [
        "## Plotting and Aggregating\n",
        "\n",
        "Let's take a few minutes here just to plot our data a bit and also do some aggregation.\n",
        "\n",
        "We're going to use the visualization library `seaborn`.  I think it's easier to use than matplotlib, which is perfect for this course as it's not a viz course! It's built off of matplotlib so we need to bring that in as well.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcf7TJyG3V8e"
      },
      "source": [
        "First we'll make a quick scatterplot of all our songs.  We'll color the points by artist.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVcLAJ9Nse_Y"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plot = sns.scatterplot(data = top_track_info,\n",
        "           x = 'track_popularity',\n",
        "           y = 'followers',\n",
        "           hue = 'artist_name')\n",
        "\n",
        "plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zicoWr5k4B1I"
      },
      "source": [
        "Well, that's not ideal.  We have so many artists that we can't really distinguish the different colors. Let's sample our data to just say 6 levels and plot those.  \n",
        "\n",
        "To sample I'm randomly selecting six artists by name using `artist_info['artist_name'].sample(6)`.  I'm then filtering the `top_track_info` dataframe to include only values that are in that sample of names using `isin()`.\n",
        "\n",
        "If you run the plot repeatedly it'll generate a new sample each time.  Give it a go to see how different artists relate to one another!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eas_0PkU4ALI"
      },
      "outputs": [],
      "source": [
        "plot = sns.scatterplot(data = top_track_info[top_track_info['artist_name'].isin(artist_info['name'].sample(6))],\n",
        "           x = 'track_popularity',\n",
        "           y = 'followers',\n",
        "           hue = 'artist_name',\n",
        "           s = 200)\n",
        "\n",
        "plot.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_QZlgymrhGw"
      },
      "source": [
        "## Rolling it up!\n",
        "\n",
        "We learned how to do data aggregations. It would be a good idea to do the same here as you might be more interested in the average track_popularty of an artist vs. number of followers.  We can use a `.groupby().agg()` process like last time to group by artist name and then aggregate track info like popularity or duration.\n",
        "\n",
        "One thing to note.  `groupby()` will automatically set whatever grouping level you use as the index.  This would be fine and you could graph with that. But, I'd rather just keep the artist_name column as an actual column and not as an index.  This  means inside `groupby()` you just add an additional argument `groupby(['artist_name'], as_index = False)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFwU0cGUrZSl"
      },
      "outputs": [],
      "source": [
        "art_track_agg = top_track_info.groupby(['artist_name'], as_index = False).agg({'track_popularity': ['mean'],\n",
        "                                                                        'track_duration_ms': ['mean']})\n",
        "art_track_agg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N4uwmaG8O1i"
      },
      "source": [
        "Cool!  Let's take a minute to rename those columns. We'll also join back on some of the general info about the artists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq44RHf-8Rvn"
      },
      "outputs": [],
      "source": [
        "# Rename like last time\n",
        "art_track_agg.columns = ['artist_name', 'mean_popularity', 'mean_duration']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KphvDd1D8ogD"
      },
      "source": [
        "Now we can ask some general question such as what artist has the most track duration on average."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3u1tXh8-iW3"
      },
      "outputs": [],
      "source": [
        "# Most duration?\n",
        "art_track_agg[art_track_agg['mean_duration'] == art_track_agg['mean_duration'].max()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rlc1kZKm-vOk"
      },
      "outputs": [],
      "source": [
        "# Most popularity?\n",
        "art_track_agg[art_track_agg['mean_popularity'] == art_track_agg['mean_popularity'].max()]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "art_track_agg"
      ],
      "metadata": {
        "id": "rCwLItWamX4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question** [15 points]: Now as practice join the artist info back into art_track_agg and plot the mean populrity vs number of followers (Sample 10 artist instead of 6)\n"
      ],
      "metadata": {
        "id": "R-ql9DsMVHUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "-TFu9lLXmcGT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}