{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gnJUY4rMsiK"
      },
      "source": [
        "## Using prompt engineering to evaluate reviews\n",
        "\n",
        "For this practive we want to use prompt engineering and large-language models to evaluate the review text that we collected for Taco Shops from Yelp in our HW3.\n",
        "\n",
        "The first part is just collect the reviews again, which we know how to do it already."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "I3Q6Gpqhok9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install yelpapi"
      ],
      "metadata": {
        "id": "Y-SH8S6AvZ4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK9qOuArYia8"
      },
      "source": [
        "# Now enter your API key so you can make requests\n",
        "from yelpapi import YelpAPI\n",
        "# yelp_api = YelpAPI('ENTER YOUR KEY HERE')\n",
        "api_key = 'YOUR-YELP-API-KEY'\n",
        "yelp_api = YelpAPI(api_key)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0qLoWa5SnlA"
      },
      "source": [
        "# search for taco shops and store to taco_shops\n",
        "taco_shops = yelp_api.search_query(term = 'taco',  location = 'Tucson, AZ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEM0ShY-E7Gz"
      },
      "source": [
        "# Flatten to taco_shops_df\n",
        "taco_shops_df = pd.json_normalize(taco_shops['businesses'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYqZknYopfsH"
      },
      "source": [
        "# Select only necessary columns\n",
        "taco_shops_df = taco_shops_df[['id', 'alias', 'name', 'review_count', 'rating']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt4ynTOZr9wL"
      },
      "source": [
        "# Getting reviews\n",
        "import time\n",
        "taco_shops_reviews_df = list()\n",
        "\n",
        "for i in range(taco_shops_df.shape[0]):\n",
        "  reviews = yelp_api.reviews_query(id = taco_shops_df['id'][i])\n",
        "  reviews_df = pd.json_normalize(reviews, record_path='reviews')\n",
        "  reviews_df['location_id'] = taco_shops_df['id'][i]\n",
        "  taco_shops_reviews_df.append(reviews_df)\n",
        "taco_shops_reviews_df = pd.concat(taco_shops_reviews_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "taco_shops_reviews_df = taco_shops_reviews_df[['id', 'text', 'rating', 'time_created', 'location_id']]"
      ],
      "metadata": {
        "id": "OwOCOajL4hhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup prompt\n",
        "from openai import OpenAI\n",
        "\n",
        "#to get the OPENAI_API_KEY you must create account with openai.com and then use API (not chatGPT)\n",
        "client = OpenAI(\n",
        "    api_key='YOUR-OPEN-AI-API-KEY',\n",
        ")\n",
        "\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-4o\", temperature=0):\n",
        "    chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt,\n",
        "          }\n",
        "      ],\n",
        "      model=model,\n",
        "      temperature=temperature)\n",
        "    return chat_completion.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "EqbE8khQyQW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In context learning: When we want to use large-language model to solve a new task, we can create a set of example to demonstrate the task. For exmple, here we provide couple of reviews and the sentiment and ask the language model to provide the sentiment for the given review."
      ],
      "metadata": {
        "id": "WokHn0IO3nxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "template1 = \"\"\"Classify the text into neutral, negative or positive.\n",
        "Text: ```{review}```\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "#Use examples to guide LLM in template 2\n",
        "template2 = \"\"\"Classify the text into neutral, negative or positive.\n",
        "\n",
        "#add your examples here\n",
        "\n",
        "Text: ```{review}```\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "\n",
        "def format_prompt(template, review):\n",
        "  return template.format(review=review);"
      ],
      "metadata": {
        "id": "q-ImruMm2L-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test it with a simple example"
      ],
      "metadata": {
        "id": "AcuEpCroRNBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = format_prompt(template1, \"my food was not good\")\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "sro2Oo7lrlJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we create a prompt for each review and pass to the GPT-4o large-language model to determine the sentiment of the review."
      ],
      "metadata": {
        "id": "GAs8oNMYASKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Complete the loop\n",
        "review_sentiment = list()\n",
        "for i in range(taco_shops_reviews_df.shape[0]):\n",
        "  ..."
      ],
      "metadata": {
        "id": "uEY4NziDxlMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assign the result as the new column of taco_shops_reviews_df called sentiment\n",
        "..."
      ],
      "metadata": {
        "id": "L1e0LvkW4IW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the YelpAPI gives us truncated review text, so the sentiment that we get may not be consistent with the provided rating.\n"
      ],
      "metadata": {
        "id": "XLvYtAr8_pVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check\n",
        "taco_shops_reviews_df"
      ],
      "metadata": {
        "id": "DI-SyMEh5Bag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now use template2 and compare the output\n"
      ],
      "metadata": {
        "id": "oK0C_CthpN6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you modify the template to get a better output? How about adding more examples in the prompt? Write templete3 and use that."
      ],
      "metadata": {
        "id": "6OabG3Z1pO_r"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zAAFX2scaoOp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}